{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dirty-coffee",
   "metadata": {},
   "source": [
    "# Pre-Processing on the General Covid-19 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-housing",
   "metadata": {},
   "source": [
    "### traduttore.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-vaccine",
   "metadata": {},
   "source": [
    "The .json file produced had multiple languages inside the text fields, we wrote this script to translate the fields which weren't in english (\"hashtags\" and \"full_text\") to english.\n",
    "\n",
    "Everything is done through the Google Translate APIs.\n",
    "\n",
    "Due to Google Translate Limitations to a massive number of requests, the for loop below does a pre-filtering, based on the lang filed from the .json file. The lang field is filled automatically during the hydratation process, the language classification is done by machine learning algorithms.\n",
    "\n",
    "The script below is the full version, we've dived the execution in two phases: the first one worked on the \"full_text\" field, the second one worked on the \"hashtag\" filed considering that the \"full_text\" filed was already OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import string\n",
    "from google_trans_new import google_translator  \n",
    "import time\n",
    "\n",
    "data = []\n",
    "with open('dataset/general_result.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "f.close()\n",
    "\n",
    "\n",
    "index=0\n",
    "translator = google_translator()  \n",
    "for element in data:\n",
    "    if data[index]['lang']==\"en\":\n",
    "        print(str(index)+\" già inglese\")\n",
    "    else:\n",
    "        translated  = translator.translate(data[index]['full_text'],lang_tgt='en')  \n",
    "        data[index]['full_text'] = translated\n",
    "        time.sleep(1) #sleep to avoid being blocked by Google \n",
    "        #print(str(index)+\" indice\" + data[index]['full_text'])\n",
    "        for entity in data[index]['entities']['hashtags']:\n",
    "            translated = translator.translate(entity['text'],lang_tgt='en')#lang_tgt è l'alt\n",
    "            entity['text']=translated\n",
    "            time.sleep(1)  #sleep to avoid being blocked by Google\n",
    "            #print(str(index)+\" indice\" + entity['text'])\n",
    "    index=index+1\n",
    "\n",
    "\n",
    "with open('general_result_translated_full.json', 'a') as f_w:\n",
    "    for line_w in data:\n",
    "        #print(\"sto stampando\")\n",
    "        json.dump(line_w, f_w)\n",
    "        f_w.write('\\n')\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
