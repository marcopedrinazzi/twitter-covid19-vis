{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "listed-surface",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis - Fake Covid-19 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-cheese",
   "metadata": {},
   "source": [
    "We've used the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preceding-marble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "#from textblob import TextBlob\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import json\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "import altair as alt\n",
    "from dateutil.parser import parse\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-assumption",
   "metadata": {},
   "source": [
    "Then we have defined the following functions to clean the tweets' text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "twenty-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dataframe = pd.read_csv('fakecovid/dataset/FINAL_fakecovid_final_filtered_dataset_clean.csv',sep=\";\")\n",
    "csv_dataframe['tweet_id'] = csv_dataframe['tweet_id'].astype(str)\n",
    "csv_list = csv_dataframe.values.tolist()\n",
    "lista_unica_csv=list(itertools.chain.from_iterable(csv_list))\n",
    "\n",
    "data = []\n",
    "with open('fakecovid/dataset/fakecovid_result_final_translated_full.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-symposium",
   "metadata": {},
   "source": [
    "We'll count how many #covid19 hashatags are positive, neutral or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "material-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_list = []\n",
    "neutral_list_false = []\n",
    "negative_list_false = []\n",
    "positive_list_false = []\n",
    "\n",
    "neutral_list_pfalse = []\n",
    "negative_list_pfalse = []\n",
    "positive_list_pfalse = []\n",
    "\n",
    "index=0\n",
    "\n",
    "for element in data:\n",
    "    token_id = data[index]['id_str']\n",
    "    indice_csv = lista_unica_csv.index(token_id)\n",
    "    \n",
    "    for entity in data[index]['entities']['hashtags']:\n",
    "        if entity['text'] == 'covid19':\n",
    "            hashtag_list.append(data[index]['full_text'])\n",
    "            score = SentimentIntensityAnalyzer().polarity_scores(data[index]['full_text'])\n",
    "        \n",
    "            if lista_unica_csv[indice_csv+1].lower() == \"false\":\n",
    "                neg = score['neg']\n",
    "                neu = score['neu']\n",
    "                pos = score['pos']\n",
    "                \n",
    "                if neg > pos:\n",
    "                    negative_list_false.append(data[index]['full_text'])\n",
    "        \n",
    "                elif pos > neg:\n",
    "                    positive_list_false.append(data[index]['full_text'])\n",
    "        \n",
    "                elif pos == neg:\n",
    "                    neutral_list_false.append(data[index]['full_text'])\n",
    "            \n",
    "            elif lista_unica_csv[indice_csv+1].lower() == \"partially false\":\n",
    "                neg = score['neg']\n",
    "                neu = score['neu']\n",
    "                pos = score['pos']\n",
    "                \n",
    "                if neg > pos:\n",
    "                    negative_list_pfalse.append(data[index]['full_text'])\n",
    "\n",
    "                elif pos > neg:\n",
    "                    positive_list_pfalse.append(data[index]['full_text'])\n",
    "        \n",
    "                elif pos == neg:\n",
    "                    neutral_list_pfalse.append(data[index]['full_text'])\n",
    "          \n",
    "    index=index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "about-impossible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets containing #covid19:  3\n",
      "\n",
      "Positive number (False):  0\n",
      "Negative number (False):  1\n",
      "Neutral number (False):  1\n",
      "\n",
      "Positive number (Partially False):  1\n",
      "Negative number (Partially False):  0\n",
      "Neutral number (Partially False):  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tweets containing #covid19: \",len(hashtag_list))\n",
    "print(\"\\nPositive number (False): \",len(positive_list_false))\n",
    "print(\"Negative number (False): \", len(negative_list_false))\n",
    "print(\"Neutral number (False): \",len(neutral_list_false))\n",
    "\n",
    "print(\"\\nPositive number (Partially False): \",len(positive_list_pfalse))\n",
    "print(\"Negative number (Partially False): \", len(negative_list_pfalse))\n",
    "print(\"Neutral number (Partially False): \",len(neutral_list_pfalse))\n",
    "\n",
    "category = []\n",
    "\n",
    "categorypositivefalse = [\"Positive false\"] * len(positive_list_false)\n",
    "categoryneutralfalse = [\"Neutral false\"] * len(neutral_list_false)\n",
    "categorynegativefalse = [\"Negative false\"] * len(negative_list_false)\n",
    "\n",
    "categorypositivepfalse = [\"Positive partiallyfalse\"] * len(positive_list_pfalse)\n",
    "categoryneutralpfalse = [\"Neutral partiallyfalse\"] * len(neutral_list_pfalse)\n",
    "categorynegativepfalse = [\"Negative partiallyfalse\"] * len(negative_list_pfalse)\n",
    "\n",
    "category = categorypositivefalse + categoryneutralfalse + categorynegativefalse + categorypositivepfalse + categoryneutralpfalse + categorynegativepfalse\n",
    "\n",
    "fdist = dict(nltk.FreqDist(category))\n",
    "\n",
    "df_fake5 = pd.DataFrame.from_dict(fdist, orient='index').reset_index()\n",
    "df_fake5 = df_fake5.rename(columns={'index':'Category', 0:'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "minor-width",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-6dea5aa9a37247568f47a0c9737d8882\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6dea5aa9a37247568f47a0c9737d8882\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6dea5aa9a37247568f47a0c9737d8882\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 13, \"titleFontSize\": 15, \"titlePadding\": 15}, \"header\": {\"labelFontSize\": 12, \"titleFontSize\": 15}, \"legend\": {\"labelFontSize\": 12, \"titleFontSize\": 14, \"titlePadding\": 10}, \"title\": {\"fontSize\": 17, \"offset\": 25}}, \"data\": {\"name\": \"data-e9104dcf02bf60b7e3d95d5099c29310\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"key\", \"scale\": {\"range\": [\"#0C7BDC\", \"#FFC20A\"]}, \"title\": \"Category\"}, \"column\": {\"type\": \"nominal\", \"field\": \"Category\", \"title\": \"Sentiment\"}, \"x\": {\"type\": \"nominal\", \"axis\": {\"labels\": false}, \"field\": \"key\", \"title\": null}, \"y\": {\"type\": \"quantitative\", \"field\": \"value\", \"title\": \"Count\"}}, \"title\": \"Sentiment analysis on #covid19 - Fake Covid-19 dataset\", \"transform\": [{\"fold\": [\"False\", \"Partially False\"]}], \"width\": 75, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-e9104dcf02bf60b7e3d95d5099c29310\": [{\"Category\": \"Neutral\", \"False\": 1, \"Partially False\": 0, \"Count\": 1}, {\"Category\": \"Negative\", \"False\": 1, \"Partially False\": 0, \"Count\": 1}, {\"Category\": \"Positive\", \"False\": 0, \"Partially False\": 1, \"Count\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_one_list = df_fake5['Category'].tolist()\n",
    "col_two_list = df_fake5['Count'].tolist()\n",
    "typelist=[]\n",
    "namelist=[]\n",
    "\n",
    "index = 0\n",
    "\n",
    "count_false = [0] * len(col_one_list)\n",
    "count_part = [0] * len(col_one_list)\n",
    "\n",
    "for el in col_one_list:\n",
    "    tok = el.split()\n",
    "    namelist.append(tok[0])\n",
    "    if tok[0] in namelist:\n",
    "        indx = namelist.index(tok[0])\n",
    "        if tok[1] == \"false\":\n",
    "            count_false[indx] = col_two_list[index]\n",
    "        elif tok[1] == \"partiallyfalse\":\n",
    "            count_part[indx] = col_two_list[index]\n",
    "        else:\n",
    "            print(\"errore count\")\n",
    "    index = index + 1\n",
    "\n",
    "i=0\n",
    "for el in col_two_list:\n",
    "    col_two_list[i] = count_false[i] + count_part[i]\n",
    "    i = i + 1\n",
    "\n",
    "df_fake5['Category']=namelist\n",
    "df_fake5['False']=count_false\n",
    "df_fake5['Partially False']=count_part\n",
    "del df_fake5['Count']\n",
    "df_fake5['Count'] = df_fake5['False'] + df_fake5['Partially False']\n",
    "\n",
    "range_ = [\"#0C7BDC\",\"#FFC20A\"]\n",
    "\n",
    "\n",
    "bars = alt.Chart(df_fake5).transform_fold(\n",
    "    ['False', 'Partially False']\n",
    ").mark_bar().encode(\n",
    "    x=alt.X('key:N',title=None,axis=alt.Axis(labels=False)),\n",
    "    y=alt.Y('value:Q',title=\"Count\"),\n",
    "    color=alt.Color('key:N', scale=alt.Scale(range=range_),title=\"Category\"),\n",
    "    column= alt.Column('Category:N', title=\"Sentiment\")\n",
    ").properties(\n",
    "    title=\"Sentiment analysis on #covid19 - Fake Covid-19 dataset\", \n",
    "    width=75\n",
    ").configure_title(\n",
    "    fontSize=17,\n",
    "    offset=25\n",
    ").configure_axis(\n",
    "    labelFontSize=13,\n",
    "    titleFontSize=15,\n",
    "    titlePadding=15\n",
    ").configure_legend(\n",
    "    titleFontSize=14,\n",
    "    labelFontSize=12,\n",
    "    titlePadding=10\n",
    ").configure_header(\n",
    "    titleFontSize=15,\n",
    "    labelFontSize=12\n",
    ")\n",
    "\n",
    "bars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
